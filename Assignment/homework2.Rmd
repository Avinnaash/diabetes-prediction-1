---
title: "Homework 2"
author: "Name1, Name2 and Name3"
date: '2017-10-04'
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
```


## Question 1 (Chapter 3, #3, 6 marks)

(a) For fixed IQ and GPA, the difference in salary between female and male is:
$$\beta_3 + \beta_5*GPA = 35 - 10 GPA$$
Therefore, (iii) is Correct. When GPA is high enough (more than 3.5), males earn more on average than females.

(b) Salary of a female with IQ of 110 and a GPA of 4.0 is 137.1 (thousand dollars), or $137,100.
50 + 20*4.0 + 0.07*110 + 35*1 + 0.01*110*4.0 - 10 *4.0 = 137.1

(c) False. We should not look at the magnitute of the coefficient because such magnitute can change if we change the scale of measurement. Instead, we should conduct hypothesis test:
$$H_0: \hat\beta_4=0$$
$$H_a: Otherwise$$
We should look at p-value of t-test or F-test to evaluate if there is significant evidence of such interaction term.

## Question 2 (Chapter 3, #9, 10 marks)

```{r}
library(ISLR) 
data(Auto)
library(dplyr)
```

(a) Scatterplot Matrix:
```{r}
pairs(Auto)
```

(b) Correlation:
```{r}
cor(Auto[1:8])
```

(c) Since origin can be considered a qualitative variable, we will treat it as a factor.
```{r}
Auto$origin <- factor(Auto$origin)
mod.fit <- lm(formula= mpg ~ . - name, data=Auto)
summary(mod.fit)
```
(i) Yes, p-value of F-test is much smaller than 0.05. So, there is relationship between the predictors and the response.
(ii) The following predictors have p-value of t-test less than 0.05, suggesting they have statistically significant relationship with the response: displacement, weight, year, and origin.
(iii) Coefficent of "year" suggests that the increasing "year" by 1 would increase "mpg" by 0.777 on average, given all other predictors remain constant. That is, cars become more fuel efficient every year by 0.777 mpg per year.

(d) Plot residual:
```{r}
par(mfrow = c(2, 2))
plot(mod.fit)
```

The Residuals vs Fitted plot suggest non-linearity in the data.
The Q-Q plot of standardized residuals suggest normal distribution of error terms but right skewed.
The Scale-Location plot suggests heteroscedasticity in the error term.
Examining standardized residuals, we notice a number of outliers with standardized residuals beyond +2,-2 and even 3. There are also a few influential points (with Cook's distance beyond 0.5).

(e) Model with interation terms
```{r}
mod.inter.fit <- lm(formula= mpg ~ (. - name):(. - name), data=Auto)
summary(mod.inter.fit)
```

Several interaction terms appear to be statistically significant (p-value of t-test less than 0.05): cylinders:acceleration, acceleration:year, acceleration:origin, and year:origin.

(f) To keep the investigation of transformations manageable, try transformations of the `weight` variable only.
```{r}
Auto$logweight <- log(Auto$weight)
Auto$sqrtweight <- log(Auto$weight)
Auto$sqweight <- (Auto$weight)^2
par(mfrow = c(2, 2))
plot(Auto$weight, Auto$mpg)
plot(Auto$logweight, Auto$mpg)
plot(Auto$sqrtweight, Auto$mpg)
plot(Auto$sqweight, Auto$mpg)
```

The log and sqrt transformation of weight seems to be most linear with mpg, while square transformation would probably make the non-linearity problem worse.
```{r}
mod.log.fit <- lm(formula= mpg ~ . - name - weight - sqrtweight - sqweight, data=Auto)
mod.sqrt.fit <- lm(formula= mpg ~ . - name - weight - logweight - sqweight, data=Auto)
mod.sq.fit <- lm(formula= mpg ~ . - name - weight - logweight - sqrtweight, data=Auto)
```

Diagnosis of the model fit using log weight:
```{r}
par(mfrow = c(2, 2))
plot(mod.log.fit)
```

Diagnosis of the model fit using sqrt weight:
```{r}
par(mfrow = c(2, 2))
plot(mod.sqrt.fit)
```

Diagnosis of the model fit using square of weight:
```{r}
par(mfrow = c(2, 2))
plot(mod.sq.fit)
```

As we can see, using log or sqrt transformation helps reduce non-linearity in the data, while using square transformation does not.

## Question 3 (Chapter 4, #4, 7 marks)

(a) Since X is uniformly distributed in [0,1], on average we would use 10% of the available observations to make the prediction.

(b) With p = 2, we would use $0.1^2 = 0.01$ or 1% of the available observations to make the prediction.

(c) With p = 100, we would use $0.1^{100}$ of the available observations to make the prediction.

(d) As we can see, as the number of features/dimensions increase, the fraction of available data we use to make prediction decrease exponentially, given the same "near" criteria. Therefore, a drawback of KNN when p is large is that there are very few training observations "near" any given test observation.

(e) The volume of p-dimensional hypercube with length $l$ is $l^p$. Since each dimension is uniformly distributed in [0,1], the volume of all training observations is 1.
We need to find length $l$ so that $l^p=0.1$ or $l=\sqrt[p]{0.1}$.

p = 1. We have $l = 0.1$

p = 2. We have $l=\sqrt{0.1} = 0.3162$

...

p = 100. We hve $l=\sqrt[100]{0.1} = 0.9772$

## Question 4 (Chapter 4, #10 parts (a)-(h), 9 marks)
```{r}
library(MASS)
library(class)
library(ISLR) 
data(Weekly)
library(dplyr)
```

(a) Graphical and Numerical summaries:
```{r}
pairs(Weekly[1:8])
```

```{r}
cor(Weekly[1:8])
```

Today's return does not seems to correlate with any lag variable. That means there appears to be little correlation between today's returns and previous days' returns.
Year and Volume seem to be highly correlated.
```{r}
plot(Weekly$Year, Weekly$Volume)
```

(b) Logistics Regression Model:
```{r}
mod.fit <- glm(Direction ~ Lag1 + Lag2 + Lag3 + Lag4 + Lag5 + Volume, data = Weekly, family = binomial(link='logit'))
summary(mod.fit)
```

Lag2 is the only variable statistically significant in the model (p-value of t-test less than 0.05). 

(c) Confusion Matrix:
```{r}
contrasts(Weekly$Direction)
```
R has created a dummy variable for Direction with value 1 - "Up" and 0 "Down".

```{r}
mod.probs <- predict(mod.fit, type = "response")
mod.pred <- rep("Down", length(mod.probs))
mod.pred[mod.probs > 0.5] <- "Up"
table(mod.pred, Weekly$Direction)
```

The overall fraction of correct prediction is 56.10%
```{r}
mean(mod.pred==Weekly$Direction)
```

Two types of mistakes made by the model:
- False positive (Type I): The model predicts "Up" when the Direction is actually "Down". The false positive rate of the model is $430/(430+54)=0.8884$
- False negative (Type II): The model predicts "Down" when the Direction is actually "Up". The false negative rate of the model is $48/(48+557)=0.0793$

(d)
```{r}
train <- (Weekly$Year <2009)
Weekly.train <- Weekly[train,]
Weekly.test <- Weekly[!train,]
mod.train.fit <- glm(Direction ~ Lag2, data = Weekly.train, family = binomial(link='logit'))
summary(mod.train.fit)
```

```{r}
mod.test.probs <- predict(mod.train.fit, Weekly.test, type = "response")
mod.test.pred <- rep("Down", length(mod.test.probs))
mod.test.pred[mod.test.probs > 0.5] <- "Up"
table(mod.test.pred, Weekly.test$Direction)
mean(mod.test.pred == Weekly.test$Direction)
```
The overall fraction of correct prediction is 62.5% on held out data.

(e) Linear Discriminant Analysis:
```{r}
lda.train.fit <- lda(Direction ~ Lag2, data = Weekly.train)
lda.train.fit
```

```{r}
lda.test.pred <- predict(lda.train.fit, Weekly.test, type = "response")$class
table(lda.test.pred, Weekly.test$Direction)
mean(lda.test.pred == Weekly.test$Direction)
```
The overall fraction of correct prediction is 62.5% on held out data. The result is very similar to that of Logistic Regression model.

(f) Quadratic Discriminant Analysis
```{r}
qda.train.fit <- qda(Direction ~ Lag2, data = Weekly.train)
qda.train.fit
```

```{r}
qda.test.pred <- predict(qda.train.fit, Weekly.test, type = "response")$class
table(qda.test.pred, Weekly.test$Direction)
mean(qda.test.pred == Weekly.test$Direction)
```

The overall fraction of correct prediction is 58.65% on held out data. QDA always predicts "Up" on held out data and it has worse accuracy compared to Logistic Regression and LDA, suggesting that the quadratic form assumed by QDA may not capture the true relationship compared to the linear forms assumed by LDA and logistic regression.

(g) K-Nearest Neighbours:
```{r}
train.X <- as.matrix(Weekly.train$Lag2)
test.X <- as.matrix(Weekly.test$Lag2)
set.seed(1)
knn.test.pred <- knn(train.X, test.X, Weekly.train$Direction, k = 1)
table(knn.test.pred, Weekly.test$Direction)
mean(knn.test.pred == Weekly.test$Direction)
```

The overall fraction of correct prediction is 50% on held out data, probably because K=1 results in overly flexible model.

(h) Based on accuracy, Logistic Regression and LDA seem to provide the best result on this dataset.

(i) DO NOT HAND IN THIS PART (though you are, of course, free to do it on your own).