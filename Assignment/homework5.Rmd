---
title: "Homework 5"
author: "Bui Le Linh"
date: '2017-12-01'
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Question 1 (Chapter 10, #8, 4 marks)

a) (1 mark)
```{r}
pr.out <- prcomp(USArrests, scale = TRUE)
pr.var <- pr.out$sdev^2
pve <- pr.var/sum(pr.var)
pve
```

b) (3 marks)
```{r}
pr.loadings <- pr.out$rotation
USArrests.scale <- scale(USArrests)
sum.var <- sum(apply(as.matrix(USArrests.scale)^2, 2, sum))
pr.var <- apply((as.matrix(USArrests.scale) %*% pr.loadings)^2, 2, sum)
pve <- pr.var/sum.var
pve
```

Both approaches show that the first principal component explains 62.0% of the variance in the data, the second principal component explains 24.7% of the variance, the third principal component explains 8.9% of the variance, and the fourth principal component explains 4.4% of the variance

## Question 2 (Chapter 10, #9, 7 marks)

a) (1 mark)
```{r}
set.seed(1)
hc.complete <- hclust(dist(USArrests), method="complete")
plot(hc.complete, main="Hierachical Clustering with Complete Linkage", xlab="", sub ="", cex =.9)
```

b) (2 marks)
```{r}
clusters.complete <- cutree(hc.complete, 3)
clusters.complete
```

c) (2 marks)
```{r}
USArrests.scale <- scale(USArrests)
hc.complete.scale <- hclust(dist(USArrests.scale), method ="complete")
plot(hc.complete.scale, main="Hierachical Clustering with Complete Linkage and Scaled features", xlab="", sub ="", cex =.9)
```

d) (2 marks)
```{r}
clusters.complete.scale <- cutree(hc.complete.scale, 3)
clusters.complete.scale
```

We construct a contingency table to compare the cluster assignment between with and without scaling features:
```{r}
table(clusters.complete, clusters.complete.scale)
```

There are 22 out of 50 obervations that are assigned differently between the clustering with and without scaling features.

Looking at the dataset USArrests:
```{r}
summary(USArrests)
```

We can see that the variables have vastly different scales. If we don't scale the variables, the caculated Euclidian distance would be driven by the Assault variable, since it has by far the largest scale. Therefore, the variables should be scaled before the inter-observation dissimilarities are computed.


